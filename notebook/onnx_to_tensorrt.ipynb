{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c3fdd1a-c4e7-4c8c-b21d-f75ae9f9fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036245f-936b-4291-b56b-a470ac30fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting export with TensorRT {trt.__version__}...\")\n",
    "logger = trt.Logger(trt.Logger.INFO)\n",
    "\n",
    "# Engine builder\n",
    "builder = trt.Builder(logger)\n",
    "config = builder.create_builder_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d223bf9-bff4-42aa-913e-448b32b4a695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/05/2024-03:11:18] [TRT] [I] ----------------------------------------------------------------\n",
      "[12/05/2024-03:11:18] [TRT] [I] Input filename:   model.onnx\n",
      "[12/05/2024-03:11:18] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[12/05/2024-03:11:18] [TRT] [I] Opset version:    14\n",
      "[12/05/2024-03:11:18] [TRT] [I] Producer name:    pytorch\n",
      "[12/05/2024-03:11:18] [TRT] [I] Producer version: 1.11.0\n",
      "[12/05/2024-03:11:18] [TRT] [I] Domain:           \n",
      "[12/05/2024-03:11:18] [TRT] [I] Model version:    0\n",
      "[12/05/2024-03:11:18] [TRT] [I] Doc string:       \n",
      "[12/05/2024-03:11:18] [TRT] [I] ----------------------------------------------------------------\n",
      "input \"images\" with shape(1, 3, 224, 224) DataType.FLOAT\n",
      "output \"output0\" with shape(1, 2) DataType.FLOAT\n"
     ]
    }
   ],
   "source": [
    "# config.max_workspace_size = 2\n",
    "flag = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "network = builder.create_network(flag)\n",
    "half = True\n",
    "\n",
    "# Read ONNX file\n",
    "parser = trt.OnnxParser(network, logger)\n",
    "if not parser.parse_from_file('model.onnx'):\n",
    "    raise RuntimeError(f\"failed to load ONNX file: {f_onnx}\")\n",
    "\n",
    "# Network inputs\n",
    "inputs = [network.get_input(i) for i in range(network.num_inputs)]\n",
    "outputs = [network.get_output(i) for i in range(network.num_outputs)]\n",
    "for inp in inputs:\n",
    "    print(f'input \"{inp.name}\" with shape{inp.shape} {inp.dtype}')\n",
    "for out in outputs:\n",
    "    print(f'output \"{out.name}\" with shape{out.shape} {out.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af72443a-ca9b-47e6-8d54-82951d4aa072",
   "metadata": {},
   "outputs": [],
   "source": [
    "if half:\n",
    "    config.set_flag(trt.BuilderFlag.FP16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25877052-17e4-4d4d-9483-5e266f0d31d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_737/1153334667.py:3: DeprecationWarning: Use build_serialized_network instead.\n",
      "  with build(network, config) as engine, open('model.engine', \"wb\") as t:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/05/2024-03:13:52] [TRT] [I] ---------- Layers Running on DLA ----------\n",
      "[12/05/2024-03:13:52] [TRT] [I] ---------- Layers Running on GPU ----------\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_0 + PWN(Clip_3)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_4 + PWN(Clip_7)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_8\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_9 + PWN(Clip_12)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_13 + PWN(Clip_16)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_17\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_18 + PWN(Clip_21)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_22 + PWN(Clip_25)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_26 + Add_27\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_28 + PWN(Clip_31)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_32 + PWN(Clip_35)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_36\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_37 + PWN(Clip_40)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_41 + PWN(Clip_44)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_45 + Add_46\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_47 + PWN(Clip_50)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_51 + PWN(Clip_54)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_55 + Add_56\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_57 + PWN(Clip_60)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_61 + PWN(Clip_64)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_65\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_66 + PWN(Clip_69)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_70 + PWN(Clip_73)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_74 + Add_75\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_76 + PWN(Clip_79)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_80 + PWN(Clip_83)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_84 + Add_85\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_86 + PWN(Clip_89)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_90 + PWN(Clip_93)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_94 + Add_95\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_96 + PWN(Clip_99)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_100 + PWN(Clip_103)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_104\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_105 + PWN(Clip_108)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_109 + PWN(Clip_112)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_113 + Add_114\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_115 + PWN(Clip_118)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_119 + PWN(Clip_122)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_123 + Add_124\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_125 + PWN(Clip_128)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_129 + PWN(Clip_132)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_133\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_134 + PWN(Clip_137)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_138 + PWN(Clip_141)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_142 + Add_143\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_144 + PWN(Clip_147)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_148 + PWN(Clip_151)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_152 + Add_153\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_154 + PWN(Clip_157)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_158 + PWN(Clip_161)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_162\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Conv_163 + PWN(Clip_166)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] GlobalAveragePool_167\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] Gemm_169\n",
      "[12/05/2024-03:13:52] [TRT] [I] [GpuLayer] (Unnamed Layer* 101) [Shuffle]\n",
      "[12/05/2024-03:13:52] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 957, GPU 3842 (MiB)\n",
      "[12/05/2024-03:13:52] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 957, GPU 3842 (MiB)\n",
      "[12/05/2024-03:13:52] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[12/05/2024-03:13:55] [TRT] [I] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n",
      "[12/05/2024-03:14:51] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[12/05/2024-03:14:52] [TRT] [I] Total Host Persistent Memory: 104832\n",
      "[12/05/2024-03:14:52] [TRT] [I] Total Device Persistent Memory: 4936192\n",
      "[12/05/2024-03:14:52] [TRT] [I] Total Scratch Memory: 0\n",
      "[12/05/2024-03:14:52] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 11 MiB, GPU 40 MiB\n",
      "[12/05/2024-03:14:52] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 7.82753ms to assign 4 blocks to 63 nodes requiring 7024640 bytes.\n",
      "[12/05/2024-03:14:52] [TRT] [I] Total Activation Memory: 7024640\n",
      "[12/05/2024-03:14:52] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 964, GPU 3834 (MiB)\n",
      "[12/05/2024-03:14:52] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 964, GPU 3834 (MiB)\n",
      "[12/05/2024-03:14:52] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +3, GPU +8, now: CPU 6, GPU 16 (MiB)\n"
     ]
    }
   ],
   "source": [
    "# Write file\n",
    "build = builder.build_engine\n",
    "with build(network, config) as engine, open('model.engine', \"wb\") as t:\n",
    "    # Metadata\n",
    "    meta = json.dumps({'model': 'mobilenet_v2', 'athor': 'vdvu'})\n",
    "    t.write(len(meta).to_bytes(4, byteorder=\"little\", signed=True))\n",
    "    t.write(meta.encode())\n",
    "    # Model\n",
    "    t.write(engine.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1d3cedd-f908-4ede-9ce5-2fc3727f7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bbcf74-b5f1-4ce6-a8a3-31636a27f2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "post-moderate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
